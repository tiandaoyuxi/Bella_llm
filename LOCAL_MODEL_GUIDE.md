# 贝拉本地模型使用指南

## 🤖 支持的AI能力

### 当前集成的AI功能：

1. **本地情感分析** (Transformers.js)
   - 实时分析文本情感
   - 无需网络连接
   - 轻量级模型

2. **本地语音识别** (Whisper)
   - 支持中文语音识别
   - 浏览器端运行
   - 隐私保护

3. **Ollama LLM对话** (可选)
   - 本地大语言模型
   - 智能对话生成
   - 可自定义模型

## 🚀 使用方式

### 基础模式（无需额外安装）
直接打开 `index.html` 即可使用：
- 语音识别
- 情感分析
- 视频轮播
- 基础关键词反应

### 增强模式（需要Ollama）
1. 安装Ollama
2. 下载LLM模型
3. 启动服务器
4. 享受智能对话

## 📊 性能对比

| 功能 | 基础模式 | 增强模式 |
|------|----------|----------|
| 启动速度 | 极快 | 中等 |
| 内存占用 | 低 | 中-高 |
| 对话智能度 | 基础 | 高 |
| 网络需求 | 无 | 无 |
| 安装复杂度 | 无 | 中等 |

## 🎯 推荐配置

### 轻量级使用
- 直接使用基础模式
- 适合快速体验
- 资源占用最小

### 完整体验
- 使用Ollama + llama3.2模型
- 获得最佳对话体验
- 需要4GB+内存

## 🔧 模型选择建议

### Ollama模型推荐：

**轻量级（2-4GB内存）：**
- `llama3.2:1b` - 最轻量
- `gemma2:2b` - 平衡选择

**标准配置（8GB+内存）：**
- `llama3.2:3b` - 推荐
- `qwen2.5:7b` - 中文优化

**高性能（16GB+内存）：**
- `llama3.2:7b` - 高质量
- `gemma2:9b` - 最佳体验

## 💡 使用技巧

1. **首次使用**：建议先体验基础模式
2. **性能优化**：关闭不必要的浏览器标签页
3. **模型切换**：可以随时在server.js中更换模型
4. **对话技巧**：与贝拉对话时保持自然，她会记住对话上下文

---

选择适合您设备的模式，开始与贝拉的美妙旅程吧！ 🌸